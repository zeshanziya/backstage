/*! For license information please see 681ec847.f9f2377d.js.LICENSE.txt */
"use strict";(self.webpackChunkbackstage_microsite=self.webpackChunkbackstage_microsite||[]).push([[345809],{305507:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>l});var o=n(824246),a=n(511151);const r={id:"external-integrations",title:"External integrations",description:"Documentation on External integrations to integrate systems with Backstage"},s=void 0,i={id:"features/software-catalog/external-integrations",title:"External integrations",description:"Documentation on External integrations to integrate systems with Backstage",source:"@site/../docs/features/software-catalog/external-integrations.md",sourceDirName:"features/software-catalog",slug:"/features/software-catalog/external-integrations",permalink:"/docs/features/software-catalog/external-integrations",draft:!1,unlisted:!1,editUrl:"https://github.com/backstage/backstage/edit/master/docs/../docs/features/software-catalog/external-integrations.md",tags:[],version:"current",frontMatter:{id:"external-integrations",title:"External integrations",description:"Documentation on External integrations to integrate systems with Backstage"},sidebar:"docs",previous:{title:"Extending the model",permalink:"/docs/features/software-catalog/extending-the-model"},next:{title:"Catalog Customization",permalink:"/docs/features/software-catalog/catalog-customization"}},c={},l=[{value:"Background",id:"background",level:2},{value:"Custom Entity Providers",id:"custom-entity-providers",level:2},{value:"Creating an Entity Provider",id:"creating-an-entity-provider",level:3},{value:"Provider Mutations",id:"provider-mutations",level:3},{value:"Installing the Provider",id:"installing-the-provider",level:3},{value:"Example User Entity Provider",id:"example-user-entity-provider",level:3},{value:"Custom Processors",id:"custom-processors",level:2},{value:"Processors and the Ingestion Loop",id:"processors-and-the-ingestion-loop",level:3},{value:"Deciding on the New Locations",id:"deciding-on-the-new-locations",level:3},{value:"Creating a Catalog Data Reader Processor",id:"creating-a-catalog-data-reader-processor",level:3},{value:"Caching processing results",id:"caching-processing-results",level:3},{value:"Supporting different metadata file formats",id:"supporting-different-metadata-file-formats",level:3}];function d(e){const t=Object.assign({p:"p",a:"a",em:"em",h2:"h2",ul:"ul",li:"li",h3:"h3",code:"code",pre:"pre",ol:"ol"},(0,a.ah)(),e.components);return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(t.p,{children:["Backstage natively supports importing catalog data through the use of\n",(0,o.jsx)(t.a,{href:"/docs/features/software-catalog/descriptor-format",children:"entity descriptor YAML files"}),". However, companies that\nalready have an existing system for keeping track of software and its owners can\nleverage those systems by integrating them with Backstage. This article shows\nthe two common ways of doing that integration: by adding a custom catalog\n",(0,o.jsx)(t.em,{children:"entity provider"}),", or by adding a ",(0,o.jsx)(t.em,{children:"processor"}),"."]}),"\n",(0,o.jsx)(t.h2,{id:"background",children:"Background"}),"\n",(0,o.jsxs)(t.p,{children:["The catalog has a frontend plugin part, that communicates via a service API to\nthe backend plugin part. The backend continuously ingests data from the sources\nyou specify, to store them in its database. The details of how this works is\ndetailed in ",(0,o.jsx)(t.a,{href:"/docs/features/software-catalog/life-of-an-entity",children:"The Life of an Entity"}),". Reading that article\nfirst is recommended."]}),"\n",(0,o.jsxs)(t.p,{children:["There are two main options for how to ingest data into the catalog: making a\n",(0,o.jsx)(t.a,{href:"#custom-entity-providers",children:"custom entity provider"}),", or making a\n",(0,o.jsx)(t.a,{href:"#custom-processors",children:"custom processor"}),". They both have strengths and drawbacks,\nbut the former would usually be preferred. Both options are presented in a\ndedicated subsection below."]}),"\n",(0,o.jsx)(t.h2,{id:"custom-entity-providers",children:"Custom Entity Providers"}),"\n",(0,o.jsx)(t.p,{children:"Entity providers sit at the very edge of the catalog. They are the original\nsources of entities that form roots of the processing tree. The dynamic location\nstore API, and the static locations you can specify in your app-config, are two\nexamples of builtin providers in the catalog."}),"\n",(0,o.jsx)(t.p,{children:"Some defining traits of entity providers:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"You instantiate them individually using code in your backend, and pass them to\nthe catalog builder. Often there's one provider instance per remote system."}),"\n",(0,o.jsx)(t.li,{children:"You may be responsible for actively running them. For example, some providers\nneed to be triggered periodically by a method call to know when they are meant\nto do their job; in that case you'll have to make that happen."}),"\n",(0,o.jsx)(t.li,{children:"The timing of their work is entirely detached from the processing loops. One\nprovider may run every 30 seconds, another one on every incoming webhook call\nof a certain type, etc."}),"\n",(0,o.jsx)(t.li,{children:"They can perform detailed updates on the set of entities that they are\nresponsible for. They can make full updates of the entire set, or issue\nindividual additions and removals."}),"\n",(0,o.jsx)(t.li,{children:"Their output is a set of unprocessed entities. Those are then subject to the\nprocessing loops before becoming final, stitched entities."}),"\n",(0,o.jsx)(t.li,{children:"When they remove an entity, the entire subtree of processor-generated entities\nunder that root is eagerly removed as well."}),"\n"]}),"\n",(0,o.jsx)(t.h3,{id:"creating-an-entity-provider",children:"Creating an Entity Provider"}),"\n",(0,o.jsxs)(t.p,{children:["The recommended way of instantiating the catalog backend classes is to use the\n",(0,o.jsx)(t.code,{children:"CatalogBuilder"}),", as illustrated in the\n",(0,o.jsx)(t.a,{href:"https://github.com/backstage/backstage/blob/master/packages/backend/src/plugins/catalog.ts",children:"example backend here"}),".\nWe will create a new\n",(0,o.jsx)(t.a,{href:"https://github.com/backstage/backstage/blob/master/plugins/catalog-node/src/api/provider.ts",children:(0,o.jsx)(t.code,{children:"EntityProvider"})}),"\nsubclass that can be added to this catalog builder."]}),"\n",(0,o.jsx)(t.p,{children:"Let's make a simple provider that can refresh a set of entities based on a\nremote store. The provider part of the interface is actually tiny - you only\nhave to supply a (unique) name, and accept a connection from the environment\nthrough which you can issue writes. The rest is up to the individual provider\nimplementation."}),"\n",(0,o.jsxs)(t.p,{children:["It is up to you where you put the code for this new provider class. For quick\nexperimentation you could place it in your backend package, but we recommend\nputting all extensions like this in a backend module package of their own in the\n",(0,o.jsx)(t.code,{children:"plugins"})," folder of your Backstage repo:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-sh",children:"yarn new --select backend-module --option id=catalog\n"})}),"\n",(0,o.jsx)(t.p,{children:"The class will have this basic structure:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-ts",children:"import { UrlReader } from '@backstage/backend-common';\nimport { Entity } from '@backstage/catalog-model';\nimport {\n  EntityProvider,\n  EntityProviderConnection,\n} from '@backstage/plugin-catalog-node';\n\n/**\n * Provides entities from fictional frobs service.\n */\nexport class FrobsProvider implements EntityProvider {\n  private readonly env: string;\n  private readonly reader: UrlReader;\n  private connection?: EntityProviderConnection;\n\n  /** [1] */\n  constructor(env: string, reader: UrlReader) {\n    this.env = env;\n    this.reader = reader;\n  }\n\n  /** [2] */\n  getProviderName(): string {\n    return `frobs-${this.env}`;\n  }\n\n  /** [3] */\n  async connect(connection: EntityProviderConnection): Promise<void> {\n    this.connection = connection;\n  }\n\n  /** [4] */\n  async run(): Promise<void> {\n    if (!this.connection) {\n      throw new Error('Not initialized');\n    }\n\n    const response = await this.reader.readUrl(\n      `https://frobs-${this.env}.example.com/data`,\n    );\n    const data = JSON.parse(await response.buffer()).toString();\n\n    /** [5] */\n    const entities: Entity[] = frobsToEntities(data);\n\n    /** [6] */\n    await this.connection.applyMutation({\n      type: 'full',\n      entities: entities.map(entity => ({\n        entity,\n        locationKey: `frobs-provider:${this.env}`,\n      })),\n    });\n  }\n}\n"})}),"\n",(0,o.jsx)(t.p,{children:"This class demonstrates several important concepts, some of which are optional.\nCheck out the numbered markings - let's go through them one by one."}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsxs)(t.li,{children:["The class takes an ",(0,o.jsx)(t.code,{children:"env"})," parameter. This is only illustrative for the sake of\nthe example. We'll use this field to exhibit the type of provider where end\nusers may want or need to make multiple instances of the same provider, and\nwhat the implications would be in that case."]}),"\n",(0,o.jsxs)(t.li,{children:["The catalog requires that all registered providers return a name that is\n",(0,o.jsx)(t.em,{children:"unique"})," among those providers, and which is ",(0,o.jsx)(t.em,{children:"stable"})," over time. The reason\nfor these requirements is, the emitted entities for each provider instance\nall hang around in a closed bucket of their own. This bucket needs to be tied\nto their provider over time, and across backend restarts. We'll see below how\nthe processor emits some entities and what that means for its own bucket."]}),"\n",(0,o.jsxs)(t.li,{children:["Once the catalog engine starts up, it immediately issues the ",(0,o.jsx)(t.code,{children:"connect"})," call\nto all known providers. This forms the bond between the code and the\ndatabase. This is also an opportunity for the provider to do one-time updates\non the connection at startup if it wants to."]}),"\n",(0,o.jsxs)(t.li,{children:["At this point the provider contract is already complete. But the class needs\nto do some actual work too! In this particular example, we chose to make a\n",(0,o.jsx)(t.code,{children:"run"})," method that has to be called each time that you want to issue a sync\nwith the ",(0,o.jsx)(t.code,{children:"frobs"})," service. Let's repeat that - this is only an example\nimplementation; some providers may be written in entirely different ways,\nsuch as for example subscribing to pubsub events and only reacting to those,\nor any number of other solutions. The only point is - external stimuli happen\nsomehow, which somehow get translated to calls on the ",(0,o.jsx)(t.code,{children:"connection"})," to persist\nthe outcome of that. This example issues a ",(0,o.jsx)(t.code,{children:"fetch"})," to the right service and\nissues a full refresh of its entity bucket based on that."]}),"\n",(0,o.jsxs)(t.li,{children:["The method translates the foreign data model to the native ",(0,o.jsx)(t.code,{children:"Entity"})," form, as\nexpected by the catalog. The ",(0,o.jsx)(t.code,{children:"Entity"})," must include the\n",(0,o.jsx)(t.code,{children:"backstage.io/managed-by-location"})," and\n",(0,o.jsx)(t.code,{children:"backstage.io/managed-by-origin-location annotations"}),"; otherwise, it will not\nappear in the Catalog and will generate warning logs. The\n",(0,o.jsx)(t.a,{href:"/docs/features/software-catalog/well-known-annotations#backstageiomanaged-by-location",children:"Well-known Annotations"}),"\ndocumentation has guidance on what values to use for these."]}),"\n",(0,o.jsxs)(t.li,{children:['Finally, we issue a "mutation" to the catalog. This persists the entities in\nour own bucket, along with an optional ',(0,o.jsx)(t.code,{children:"locationKey"})," that's used for conflict\nchecks. But this is a bigger topic - mutations warrant their own explanatory\nsection below."]}),"\n"]}),"\n",(0,o.jsx)(t.h3,{id:"provider-mutations",children:"Provider Mutations"}),"\n",(0,o.jsx)(t.p,{children:"Let's circle back to the bucket analogy."}),"\n",(0,o.jsxs)(t.p,{children:["Each provider ",(0,o.jsx)(t.em,{children:"instance"}),' - not each class but each instance registered with the\ncatalog - has access to its own bucket of entities, and the bucket is identified\nby the stable name of the provider instance. Every time the provider issues\n"mutations", it changes the contents of that bucket. Nothing else outside of the\nbucket is accessible.']}),"\n",(0,o.jsx)(t.p,{children:"There are two different types of mutation."}),"\n",(0,o.jsxs)(t.p,{children:["The first is ",(0,o.jsx)(t.code,{children:"'full'"}),", which means to figuratively throw away the contents of\nthe bucket and replacing it with all of the new contents specified. Under the\nhood, this is actually implemented through a highly efficient delta mechanism\nfor performance reasons, since it is common that the difference from one run to\nthe other is actually very small. This strategy is convenient for providers that\nhave easy access to batch-fetches of the entire subject material from a remote\nsource, and doesn't have access to, or does not want to compute, deltas."]}),"\n",(0,o.jsxs)(t.p,{children:["The other mutation type is ",(0,o.jsx)(t.code,{children:"'delta'"}),", which lets the provider explicitly upsert\nor delete entities in its bucket. This mutation is convenient e.g. for event\nbased providers, and can also be more performant since no deltas need to be\ncomputed, and previous bucket contents outside of the targeted set do not have\nto be taken into account."]}),"\n",(0,o.jsxs)(t.p,{children:["In all cases, the mutation entities are treated as ",(0,o.jsx)(t.em,{children:"unprocessed"})," entities. When\nthey land in the database, the registered catalog processors go to work on them\nto transform them into final, processed and stitched, entities ready for\nconsumption."]}),"\n",(0,o.jsxs)(t.p,{children:["Every entity emitted by a processor can have a ",(0,o.jsx)(t.code,{children:"locationKey"}),", as shown above.\nThis is a critical conflict resolution key, in the form of an opaque string that\nshould be unique for each location that an entity could be located at, and\nundefined if the entity does not have a fixed location."]}),"\n",(0,o.jsxs)(t.p,{children:["In practice it should be set to the serialized location reference if the entity\nis stored in Git, for example\n",(0,o.jsx)(t.code,{children:"https://github.com/backstage/backstage/blob/master/catalog-info.yaml"}),", or a\nsimilar string that distinctly pins down its origins. In our example we set it\nto a string that was distinct for the provider class, plus its instance\nidentifying properties which in this case was the ",(0,o.jsx)(t.code,{children:"env"}),"."]}),"\n",(0,o.jsx)(t.p,{children:'A conflict between two entity definitions happen when they have the same entity\nreference, i.e. kind, namespace, and name. In the event of a conflict, such as\nif two "competing" providers try to emit entities that have the same reference\ntriplet, the location key will be used according to the following rules to\nresolve the conflict:'}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"If the entity is already present in the database but does not have a location\nkey set, the new entity wins and will override the existing one."}),"\n",(0,o.jsx)(t.li,{children:"If the entity is already present in the database the new entity will only win\nif the location keys of the existing and new entity are the same."}),"\n",(0,o.jsx)(t.li,{children:"If the entity is not already present, insert the entity into the database\nalong with the provided location key."}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:'This may seem complex, but is a vital mechanism for ensuring that users aren\'t\npermitted to do "rogue" takeovers of already registered entities that belong to\nothers.'}),"\n",(0,o.jsx)(t.h3,{id:"installing-the-provider",children:"Installing the Provider"}),"\n",(0,o.jsxs)(t.p,{children:["You should now be able to add this class to your backend in\n",(0,o.jsx)(t.code,{children:"packages/backend/src/plugins/catalog.ts"}),":"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-ts",metastring:'title="packages/backend/src/plugins/catalog.ts"',children:"/* highlight-add-next-line */\nimport { FrobsProvider } from '../path/to/class';\n\nexport default async function createPlugin(\n  env: PluginEnvironment,\n): Promise<Router> {\n  const builder = CatalogBuilder.create(env);\n  /* highlight-add-start */\n  const frobs = new FrobsProvider('production', env.reader);\n  builder.addEntityProvider(frobs);\n  /* highlight-add-end */\n\n  const { processingEngine, router } = await builder.build();\n  await processingEngine.start();\n\n  /* highlight-add-start */\n  await env.scheduler.scheduleTask({\n    id: 'run_frobs_refresh',\n    fn: async () => {\n      await frobs.run();\n    },\n    frequency: { minutes: 30 },\n    timeout: { minutes: 10 },\n  });\n  /* highlight-add-end */\n\n  // ..\n}\n"})}),"\n",(0,o.jsxs)(t.p,{children:["Note that we used the builtin scheduler facility to regularly call the ",(0,o.jsx)(t.code,{children:"run"}),"\nmethod of the provider, in this example. It is a suitable driver for this\nparticular type of recurring task. We placed the scheduling after the actual\nconstruction and startup phase of the rest of the catalog, because at that point\nthe ",(0,o.jsx)(t.code,{children:"connect"})," call has been made to the provider."]}),"\n",(0,o.jsx)(t.p,{children:"Start up the backend - it should now start reading from the previously\nregistered location and you'll see your entities start to appear in Backstage."}),"\n",(0,o.jsx)(t.h3,{id:"example-user-entity-provider",children:"Example User Entity Provider"}),"\n",(0,o.jsx)(t.p,{children:"If you have a 3rd party entity provider such as an internal HR system that you wish to use you are not limited to using our entity providers, (or simply wish to add to existing entity providers with your own data)."}),"\n",(0,o.jsx)(t.p,{children:"We can create an entity provider to read entities that are based off that provider."}),"\n",(0,o.jsxs)(t.p,{children:["We create a basic entity provider as shown above. In the example below we might want to extract our users from an HR system, I am assuming the HR system already has the slackUserId to get that information please see the ",(0,o.jsx)(t.a,{href:"https://api.slack.com/methods",children:"Slack Api"}),"."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-typescript",children:"import {\n  ANNOTATION_LOCATION,\n  ANNOTATION_ORIGIN_LOCATION,\n} from '@backstage/catalog-model'\nimport {\n  EntityProvider,\n  EntityProviderConnection,\n} from '@backstage/plugin-catalog-backend'\nimport { WebClient } from '@slack/web-api'\nimport {kebabCase} from 'lodash'\n\ninterface Staff {\n  displayName: string\n  slackUserId: string\n  jobTitle: string\n  photoUrl: string\n  address: string\n  email:string\n}\n\nexport class UserEntityProvider implements EntityProvider {\n  private readonly getStaffUrl: string\n  protected readonly slackTeam: string\n  protected readonly slackToken: string\n  protected connection?: EntityProviderConnection\n\n  static fromConfig(config: Config, options: { logger: Logger }) {\n    const getStaffUrl = config.getString('staff.url')\n    const slackToken = config.getString('slack.token')\n    const slackTeam = config.getString('slack.team')\n    return new UserEntityProvider({\n      ...options,\n      getStaffUrl,\n      slackToken,\n      slackTeam,\n    })\n  }\n\n  private constructor(options: {\n    getStaffUrl: string\n    slackToken: string\n    slackTeam: string\n  }) {\n    this.getStaffUrl = options.getStaffUrl\n    this.slackToken = options.slackToken\n    this.slackTeam = options.slackTeam\n  }\n\n  async getAllStaff(): Promise<Staff[]>{\n    await return axios.get(this.getStaffUrl)\n  }\n\n  public async connect(connection: EntityProviderConnection): Promise<void> {\n    this.connection = connection\n  }\n\n  async run(): Promise<void> {\n    if (!this.connection) {\n      throw new Error('User Connection Not initialized')\n    }\n\n    const userResources: UserEntity[] = []\n    const staff = await this.getAllStaff()\n\n    for (const user of staff) {\n      // we can add any links here in this case it would be adding a slack link to the users so you can directly slack them.\n      const links =\n        user.slackUserId != null && user.slackUserId.length > 0\n          ? [\n              {\n                url: `slack://user?team=${this.slackTeam}&id=${user.slackUserId}`,\n                title: 'Slack',\n                icon: 'message',\n              },\n            ]\n          : undefined\n      const userEntity: UserEntity = {\n        kind: 'User',\n        apiVersion: 'backstage.io/v1alpha1',\n        metadata: {\n          annotations: {\n            [ANNOTATION_LOCATION]: 'hr-user-https://www.hrurl.com/',\n            [ANNOTATION_ORIGIN_LOCATION]: 'hr-user-https://www.hrurl.com/',\n          },\n          links,\n          // name of the entity\n          name: kebabCase(user.displayName),\n          // name for display purposes could be anything including email\n          title: user.displayName,\n        },\n        spec: {\n          profile: {\n            displayName: user.displayName,\n            email: user.email,\n            picture: user.photoUrl,\n          },\n          memberOf: [],\n        },\n      }\n\n      userResources.push(userEntity)\n    }\n\n    await this.connection.applyMutation({\n      type: 'full',\n      entities: userResources.map((entity) => ({\n        entity,\n        locationKey: 'hr-user-https://www.hrurl.com/',\n      })),\n    })\n}\n\n"})}),"\n",(0,o.jsx)(t.h2,{id:"custom-processors",children:"Custom Processors"}),"\n",(0,o.jsx)(t.p,{children:"The other possible way of ingesting data into the catalog is through the use of\nlocation reading catalog processors."}),"\n",(0,o.jsx)(t.p,{children:"Processors sit in the middle of the processing loops of the catalog. They are\nresponsible for updating and finalizing unprocessed entities on their way to\nbecoming final, stitched entities. They can also, crucially, emit other entities\nwhile doing so. Those then form branches of the entity tree."}),"\n",(0,o.jsx)(t.p,{children:"Some defining traits of processors:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"You instantiate them using code in your backend, and pass them to the catalog\nbuilder. There's usually only one instance of each type, which then gets\ncalled many times over in parallel for all entities in the catalog."}),"\n",(0,o.jsx)(t.li,{children:"Their invocation is driven by the fixed processing loop. All processors are\nunconditionally repeatedly called for all entities. You cannot control this\nbehavior, besides adjusting the frequency of the loop, which then applies\nequally to all processors."}),"\n",(0,o.jsx)(t.li,{children:"They cannot control in detail the entities that they emit, the only effective\noperation is upsert on their children. If they stop emitting a certain child,\nthat child becomes marked as an orphan; no deletions are possible."}),"\n",(0,o.jsx)(t.li,{children:"Their input is an unprocessed entity, and their output is modifications to\nthat same entity plus possibly some auxiliary data including unprocessed child\nentities."}),"\n"]}),"\n",(0,o.jsx)(t.h3,{id:"processors-and-the-ingestion-loop",children:"Processors and the Ingestion Loop"}),"\n",(0,o.jsxs)(t.p,{children:["The catalog holds a number of registered locations, that were added either by\nsite admins or by individual Backstage users. Their purpose is to reference some\nsort of data that the catalog shall keep itself up to date with. Each location\nhas a ",(0,o.jsx)(t.code,{children:"type"}),", and a ",(0,o.jsx)(t.code,{children:"target"})," that are both strings."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"# Example location\ntype: url\ntarget: https://github.com/backstage/backstage/blob/master/catalog-info.yaml\n"})}),"\n",(0,o.jsxs)(t.p,{children:["The builtin catalog backend has an ingestion loop that periodically goes through\nall of these registered locations, and pushes them and their resulting output\nthrough the list of ",(0,o.jsx)(t.em,{children:"processors"}),"."]}),"\n",(0,o.jsx)(t.p,{children:"Processors are classes that the site admin has registered with the catalog at\nstartup. They are at the heart of all catalog logic, and have the ability to\nread the contents of locations, modify in-flight entities that were read out of\na location, perform validation, and more. The catalog comes with a set of\nbuiltin processors, that have the ability to read from a list of well known\nlocation types, to perform the basic processing needs, etc, but more can be\nadded by the organization that adopts Backstage."}),"\n",(0,o.jsx)(t.p,{children:"We will now show the process of creating a new processor and location type,\nwhich enables the ingestion of catalog data from an existing external API."}),"\n",(0,o.jsx)(t.h3,{id:"deciding-on-the-new-locations",children:"Deciding on the New Locations"}),"\n",(0,o.jsx)(t.p,{children:"The first step is to decide how we want to point at the system that holds our\ndata. Let's assume that it is internally named System-X and can be reached\nthrough HTTP REST calls to its API."}),"\n",(0,o.jsx)(t.p,{children:"Let's decide that our locations shall take the following form:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"type: system-x\ntarget: http://systemx.services.example.net/api/v2\n"})}),"\n",(0,o.jsxs)(t.p,{children:["It got its own made-up ",(0,o.jsx)(t.code,{children:"type"}),", and the ",(0,o.jsx)(t.code,{children:"target"})," conveniently points to the\nactual API endpoint to talk to."]}),"\n",(0,o.jsx)(t.p,{children:"So now we have to make the catalog aware of such a location so that it can start\nfeeding it into the ingestion loop. For this kind of an integration, you'd\ntypically want to add it to the list of statically always-available locations in\nthe config."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",metastring:'title="app-config.yaml"',children:"catalog:\n  locations:\n    - type: system-x\n      target: http://systemx.services.example.net/api/v2\n"})}),"\n",(0,o.jsx)(t.p,{children:"If you start up the backend now, it will start to periodically say that it could\nnot find a processor that supports that location. So let's make a processor that\ndoes so!"}),"\n",(0,o.jsx)(t.h3,{id:"creating-a-catalog-data-reader-processor",children:"Creating a Catalog Data Reader Processor"}),"\n",(0,o.jsxs)(t.p,{children:["The recommended way of instantiating the catalog backend classes is to use the\n",(0,o.jsx)(t.code,{children:"CatalogBuilder"}),", as illustrated in the\n",(0,o.jsx)(t.a,{href:"https://github.com/backstage/backstage/blob/master/packages/backend/src/plugins/catalog.ts",children:"example backend here"}),".\nWe will create a new\n",(0,o.jsx)(t.a,{href:"https://github.com/backstage/backstage/blob/master/plugins/catalog-node/src/api/processor.ts",children:(0,o.jsx)(t.code,{children:"CatalogProcessor"})}),"\nsubclass that can be added to this catalog builder."]}),"\n",(0,o.jsxs)(t.p,{children:["It is up to you where you put the code for this new processor class. For quick\nexperimentation you could place it in your backend package, but we recommend\nputting all extensions like this in a backend module package of their own in the\n",(0,o.jsx)(t.code,{children:"plugins"})," folder of your Backstage repo:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-sh",children:"yarn new --select backend-module --option id=catalog\n"})}),"\n",(0,o.jsx)(t.p,{children:"The class will have this basic structure:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-ts",children:"import { UrlReader } from '@backstage/backend-common';\nimport {\n  processingResult,\n  CatalogProcessor,\n  CatalogProcessorEmit,\n} from '@backstage/plugin-catalog-node';\n\nimport { LocationSpec } from '@backstage/plugin-catalog-common';\n\n// A processor that reads from the fictional System-X\nexport class SystemXReaderProcessor implements CatalogProcessor {\n  constructor(private readonly reader: UrlReader) {}\n\n  getProcessorName(): string {\n    return 'SystemXReaderProcessor';\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n  ): Promise<boolean> {\n    // Pick a custom location type string. A location will be\n    // registered later with this type.\n    if (location.type !== 'system-x') {\n      return false;\n    }\n\n    try {\n      // Use the builtin reader facility to grab data from the\n      // API. If you prefer, you can just use plain fetch here\n      // (from the node-fetch package), or any other method of\n      // your choosing.\n      const response = await this.reader.readUrl(location.target);\n      const json = JSON.parse((await response.buffer()).toString());\n      // Repeatedly call emit(processingResult.entity(location, <entity>))\n    } catch (error) {\n      const message = `Unable to read ${location.type}, ${error}`;\n      emit(processingResult.generalError(location, message));\n    }\n\n    return true;\n  }\n}\n"})}),"\n",(0,o.jsx)(t.p,{children:"The key points to note are:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:["Make a class that implements ",(0,o.jsx)(t.code,{children:"CatalogProcessor"})]}),"\n",(0,o.jsxs)(t.li,{children:["Only act on location types that you care about, and leave the rest alone by\nreturning ",(0,o.jsx)(t.code,{children:"false"})]}),"\n",(0,o.jsxs)(t.li,{children:["Read the data from the external system in any way you see fit. Use the\nlocation ",(0,o.jsx)(t.code,{children:"target"})," field if you designed it as mentioned above"]}),"\n",(0,o.jsxs)(t.li,{children:["Call ",(0,o.jsx)(t.code,{children:"emit"})," any number of times with the results of that process"]}),"\n",(0,o.jsxs)(t.li,{children:["Finally return ",(0,o.jsx)(t.code,{children:"true"})]}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["You should now be able to add this class to your backend in\n",(0,o.jsx)(t.code,{children:"packages/backend/src/plugins/catalog.ts"}),":"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-ts",metastring:'title="packages/backend/src/plugins/catalog.ts"',children:"/* highlight-add-next-line */\nimport { SystemXReaderProcessor } from '../path/to/class';\n\nexport default async function createPlugin(\n  env: PluginEnvironment,\n): Promise<Router> {\n  const builder = CatalogBuilder.create(env);\n  /* highlight-add-next-line */\n  builder.addProcessor(new SystemXReaderProcessor(env.reader));\n\n  // ..\n}\n"})}),"\n",(0,o.jsx)(t.p,{children:"Start up the backend - it should now start reading from the previously\nregistered location and you'll see your entities start to appear in Backstage."}),"\n",(0,o.jsx)(t.h3,{id:"caching-processing-results",children:"Caching processing results"}),"\n",(0,o.jsx)(t.p,{children:"The catalog periodically refreshes entities in the catalog, and in doing so it\ncalls out to external systems to fetch changes. This can be taxing for upstream\nservices and large deployments may get rate limited if too many requests are\nsent. Luckily many external systems provide ETag support to check for changes\nwhich usually doesn't count towards the quota and saves resources both\ninternally and externally."}),"\n",(0,o.jsxs)(t.p,{children:["The catalog has built in support for leveraging ETags when refreshing external\nlocations in GitHub. This example aims to demonstrate how to add the same\nbehavior for ",(0,o.jsx)(t.code,{children:"system-x"})," that we implemented earlier."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-ts",children:"import { UrlReader } from '@backstage/backend-common';\nimport { Entity } from '@backstage/catalog-model';\nimport {\n  processingResult,\n  CatalogProcessor,\n  CatalogProcessorEmit,\n  CatalogProcessorCache,\n  CatalogProcessorParser,\n  LocationSpec,\n} from '@backstage/plugin-catalog-node';\n\n// It's recommended to always bump the CACHE_KEY version if you make\n// changes to the processor implementation or CacheItem.\nconst CACHE_KEY = 'v1';\n\n// Our cache item contains the ETag used in the upstream request\n// as well as the processing result used when the Etag matches.\n// Bump the CACHE_KEY version if you make any changes to this type.\ntype CacheItem = {\n  etag: string;\n  entity: Entity;\n};\n\nexport class SystemXReaderProcessor implements CatalogProcessor {\n  constructor(private readonly reader: UrlReader) {}\n\n  getProcessorName() {\n    // The processor name must be unique.\n    return 'system-x-processor';\n  }\n\n  async readLocation(\n    location: LocationSpec,\n    _optional: boolean,\n    emit: CatalogProcessorEmit,\n    _parser: CatalogProcessorParser,\n    cache: CatalogProcessorCache,\n  ): Promise<boolean> {\n    // Pick a custom location type string. A location will be\n    // registered later with this type.\n    if (location.type !== 'system-x') {\n      return false;\n    }\n    const cacheItem = await cache.get<CacheItem>(CACHE_KEY);\n    try {\n      // This assumes an URL reader that returns the response together with the ETag.\n      // We send the ETag from the previous run if it exists.\n      // The previous ETag will be set in the headers for the outgoing request and system-x\n      // is going to throw NOT_MODIFIED (HTTP 304) if the ETag matches.\n      const response = await this.reader.readUrl(location.target, {\n        etag: cacheItem?.etag,\n      });\n      if (!response) {\n        // readUrl is currently optional to implement so we have to check if we get a response back.\n        throw new Error(\n          'No URL reader that can parse system-x targets installed',\n        );\n      }\n\n      // ETag is optional in the response but we need it to cache the result.\n      if (!response.etag) {\n        throw new Error(\n          'No ETag returned from system-x, cannot use response for caching',\n        );\n      }\n\n      // For this example the JSON payload is a single entity.\n      const entity: Entity = JSON.parse(response.buffer.toString());\n      emit(processingResult.entity(location, entity));\n\n      // Update the cache with the new ETag and entity used for the next run.\n      await cache.set<CacheItem>(CACHE_KEY, {\n        etag: response.etag,\n        entity,\n      });\n    } catch (error) {\n      if (error.name === 'NotModifiedError' && cacheItem) {\n        // The ETag matches and we have a cached value from the previous run.\n        emit(processingResult.entity(location, cacheItem.entity));\n      }\n      const message = `Unable to read ${location.type}, ${error}`;\n      emit(processingResult.generalError(location, message));\n    }\n\n    return true;\n  }\n}\n"})}),"\n",(0,o.jsx)(t.h3,{id:"supporting-different-metadata-file-formats",children:"Supporting different metadata file formats"}),"\n",(0,o.jsxs)(t.p,{children:["Sometimes you might already have files in GitHub or some provider that Backstage already supports but the metadata format that you use is not the same as ",(0,o.jsx)(t.code,{children:"catalog-info.yaml"})," files. In this case you can implement a custom parser that can read the files and convert them on-the-fly to the ",(0,o.jsx)(t.code,{children:"Entity"})," format that Backstage expects, and it will integrate seamlessly into Catalog so that you can use things like the ",(0,o.jsx)(t.code,{children:"GithubEntityProvider"})," to read these files."]}),"\n",(0,o.jsxs)(t.p,{children:["What you will need to do is to provide a custom ",(0,o.jsx)(t.code,{children:"CatalogProcessorParser"})," and provide that to ",(0,o.jsx)(t.code,{children:"builder.setEntityDataParser"}),"."]}),"\n",(0,o.jsx)(t.p,{children:"Let's say my format looks something like this:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"id: my-service\ntype: service\nauthor: user@backstage.com\n"})}),"\n",(0,o.jsxs)(t.p,{children:["We need to build a custom parser that can read this format and convert it to the ",(0,o.jsx)(t.code,{children:"Entity"})," format that Backstage expects."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-ts",metastring:'title="packages/backend/src/lib/customEntityDataParser.ts"',children:"import {\n  CatalogProcessorParser,\n  CatalogProcessorResult,\n  LocationSpec,\n  processingResult,\n} from '@backstage/plugin-catalog-node';\nimport yaml from 'yaml';\nimport {\n  Entity,\n  stringifyLocationRef,\n  ANNOTATION_ORIGIN_LOCATION,\n  ANNOTATION_LOCATION,\n} from '@backstage/catalog-model';\nimport _ from 'lodash';\nimport parseGitUrl from 'git-url-parse';\n\n// This implementation will map whatever your own format is into valid Entity objects.\nconst makeEntityFromCustomFormatJson = (\n  component: { id: string; type: string; author: string },\n  location: LocationSpec,\n): Entity => {\n  return {\n    apiVersion: 'backstage.io/v1alpha1',\n    kind: 'Component',\n    metadata: {\n      name: component.id,\n      namespace: 'default',\n      annotations: {\n        [ANNOTATION_LOCATION]: `${location.type}:${location.target}`,\n        [ANNOTATION_ORIGIN_LOCATION]: `${location.type}:${location.target}`,\n      },\n    }\n    spec: {\n      type: component.type,\n      owner: component.author,\n      lifecycle: 'experimental'\n    }\n  }\n};\n\nexport const customEntityDataParser: CatalogProcessorParser = async function* ({\n  data,\n  location,\n}) {\n  let documents: yaml.Document.Parsed[];\n  try {\n    // let's treat the incoming file always as yaml, you can of course change this if your format is not yaml.\n    documents = yaml.parseAllDocuments(data.toString('utf8')).filter(d => d);\n  } catch (e) {\n    // if we failed to parse as yaml throw some errors.\n    const loc = stringifyLocationRef(location);\n    const message = `Failed to parse YAML at ${loc}, ${e}`;\n    yield processingResult.generalError(location, message);\n    return;\n  }\n\n  for (const document of documents) {\n    // If there's errors parsing the document as yaml, we should throw an error.\n    if (document.errors?.length) {\n      const loc = stringifyLocationRef(location);\n      const message = `YAML error at ${loc}, ${document.errors[0]}`;\n      yield processingResult.generalError(location, message);\n    } else {\n      // Convert the document to JSON\n      const json = document.toJSON();\n      if (_.isPlainObject(json)) {\n        // Is this a catalog-info.yaml file?\n        if (json.apiVersion) {\n          yield processingResult.entity(location, json as Entity);\n\n        // let's treat this like it's our custom format instead.\n        } else {\n          yield processingResult.entity(\n            location,\n            makeEntityFromCustomFormatJson(json, location),\n          );\n        }\n      } else if (json === null) {\n        // Ignore null values, these happen if there is an empty document in the\n        // YAML file, for example if --- is added to the end of the file.\n      } else {\n        // We don't support this format.\n        const message = `Expected object at root, got ${typeof json}`;\n        yield processingResult.generalError(location, message);\n      }\n    }\n  }\n}\n"})}),"\n",(0,o.jsx)(t.p,{children:"This is a lot of code right now, as this is a pretty niche use-case, so we don't currently provide many helpers for you to be able to provide custom implementations easier or to compose together different parsers."}),"\n",(0,o.jsxs)(t.p,{children:["You then should be able to provide this ",(0,o.jsx)(t.code,{children:"customEntityDataParser"})," to the ",(0,o.jsx)(t.code,{children:"CatalogBuilder"}),":"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-ts",metastring:'title="packages/backend/src/plugins/catalog.ts"',children:"import { customEntityDataParser } from '../lib/customEntityDataParser';\n\n...\n\nbuilder.setEntityDataParser(customEntityDataParser);\n"})})]})}const h=function(e={}){const{wrapper:t}=Object.assign({},(0,a.ah)(),e.components);return t?(0,o.jsx)(t,Object.assign({},e,{children:(0,o.jsx)(d,e)})):d(e)}},371426:(e,t,n)=>{var o=n(827378),a=Symbol.for("react.element"),r=Symbol.for("react.fragment"),s=Object.prototype.hasOwnProperty,i=o.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,c={key:!0,ref:!0,__self:!0,__source:!0};function l(e,t,n){var o,r={},l=null,d=null;for(o in void 0!==n&&(l=""+n),void 0!==t.key&&(l=""+t.key),void 0!==t.ref&&(d=t.ref),t)s.call(t,o)&&!c.hasOwnProperty(o)&&(r[o]=t[o]);if(e&&e.defaultProps)for(o in t=e.defaultProps)void 0===r[o]&&(r[o]=t[o]);return{$$typeof:a,type:e,key:l,ref:d,props:r,_owner:i.current}}t.Fragment=r,t.jsx=l,t.jsxs=l},541535:(e,t)=>{var n=Symbol.for("react.element"),o=Symbol.for("react.portal"),a=Symbol.for("react.fragment"),r=Symbol.for("react.strict_mode"),s=Symbol.for("react.profiler"),i=Symbol.for("react.provider"),c=Symbol.for("react.context"),l=Symbol.for("react.forward_ref"),d=Symbol.for("react.suspense"),h=Symbol.for("react.memo"),u=Symbol.for("react.lazy"),p=Symbol.iterator;var m={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},f=Object.assign,g={};function y(e,t,n){this.props=e,this.context=t,this.refs=g,this.updater=n||m}function b(){}function v(e,t,n){this.props=e,this.context=t,this.refs=g,this.updater=n||m}y.prototype.isReactComponent={},y.prototype.setState=function(e,t){if("object"!=typeof e&&"function"!=typeof e&&null!=e)throw Error("setState(...): takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,e,t,"setState")},y.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,"forceUpdate")},b.prototype=y.prototype;var x=v.prototype=new b;x.constructor=v,f(x,y.prototype),x.isPureReactComponent=!0;var w=Array.isArray,k=Object.prototype.hasOwnProperty,j={current:null},E={key:!0,ref:!0,__self:!0,__source:!0};function T(e,t,o){var a,r={},s=null,i=null;if(null!=t)for(a in void 0!==t.ref&&(i=t.ref),void 0!==t.key&&(s=""+t.key),t)k.call(t,a)&&!E.hasOwnProperty(a)&&(r[a]=t[a]);var c=arguments.length-2;if(1===c)r.children=o;else if(1<c){for(var l=Array(c),d=0;d<c;d++)l[d]=arguments[d+2];r.children=l}if(e&&e.defaultProps)for(a in c=e.defaultProps)void 0===r[a]&&(r[a]=c[a]);return{$$typeof:n,type:e,key:s,ref:i,props:r,_owner:j.current}}function P(e){return"object"==typeof e&&null!==e&&e.$$typeof===n}var C=/\/+/g;function _(e,t){return"object"==typeof e&&null!==e&&null!=e.key?function(e){var t={"=":"=0",":":"=2"};return"$"+e.replace(/[=:]/g,(function(e){return t[e]}))}(""+e.key):t.toString(36)}function S(e,t,a,r,s){var i=typeof e;"undefined"!==i&&"boolean"!==i||(e=null);var c=!1;if(null===e)c=!0;else switch(i){case"string":case"number":c=!0;break;case"object":switch(e.$$typeof){case n:case o:c=!0}}if(c)return s=s(c=e),e=""===r?"."+_(c,0):r,w(s)?(a="",null!=e&&(a=e.replace(C,"$&/")+"/"),S(s,t,a,"",(function(e){return e}))):null!=s&&(P(s)&&(s=function(e,t){return{$$typeof:n,type:e.type,key:t,ref:e.ref,props:e.props,_owner:e._owner}}(s,a+(!s.key||c&&c.key===s.key?"":(""+s.key).replace(C,"$&/")+"/")+e)),t.push(s)),1;if(c=0,r=""===r?".":r+":",w(e))for(var l=0;l<e.length;l++){var d=r+_(i=e[l],l);c+=S(i,t,a,d,s)}else if(d=function(e){return null===e||"object"!=typeof e?null:"function"==typeof(e=p&&e[p]||e["@@iterator"])?e:null}(e),"function"==typeof d)for(e=d.call(e),l=0;!(i=e.next()).done;)c+=S(i=i.value,t,a,d=r+_(i,l++),s);else if("object"===i)throw t=String(e),Error("Objects are not valid as a React child (found: "+("[object Object]"===t?"object with keys {"+Object.keys(e).join(", ")+"}":t)+"). If you meant to render a collection of children, use an array instead.");return c}function I(e,t,n){if(null==e)return e;var o=[],a=0;return S(e,o,"","",(function(e){return t.call(n,e,a++)})),o}function N(e){if(-1===e._status){var t=e._result;(t=t()).then((function(t){0!==e._status&&-1!==e._status||(e._status=1,e._result=t)}),(function(t){0!==e._status&&-1!==e._status||(e._status=2,e._result=t)})),-1===e._status&&(e._status=0,e._result=t)}if(1===e._status)return e._result.default;throw e._result}var R={current:null},O={transition:null},A={ReactCurrentDispatcher:R,ReactCurrentBatchConfig:O,ReactCurrentOwner:j};t.Children={map:I,forEach:function(e,t,n){I(e,(function(){t.apply(this,arguments)}),n)},count:function(e){var t=0;return I(e,(function(){t++})),t},toArray:function(e){return I(e,(function(e){return e}))||[]},only:function(e){if(!P(e))throw Error("React.Children.only expected to receive a single React element child.");return e}},t.Component=y,t.Fragment=a,t.Profiler=s,t.PureComponent=v,t.StrictMode=r,t.Suspense=d,t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=A,t.cloneElement=function(e,t,o){if(null==e)throw Error("React.cloneElement(...): The argument must be a React element, but you passed "+e+".");var a=f({},e.props),r=e.key,s=e.ref,i=e._owner;if(null!=t){if(void 0!==t.ref&&(s=t.ref,i=j.current),void 0!==t.key&&(r=""+t.key),e.type&&e.type.defaultProps)var c=e.type.defaultProps;for(l in t)k.call(t,l)&&!E.hasOwnProperty(l)&&(a[l]=void 0===t[l]&&void 0!==c?c[l]:t[l])}var l=arguments.length-2;if(1===l)a.children=o;else if(1<l){c=Array(l);for(var d=0;d<l;d++)c[d]=arguments[d+2];a.children=c}return{$$typeof:n,type:e.type,key:r,ref:s,props:a,_owner:i}},t.createContext=function(e){return(e={$$typeof:c,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null}).Provider={$$typeof:i,_context:e},e.Consumer=e},t.createElement=T,t.createFactory=function(e){var t=T.bind(null,e);return t.type=e,t},t.createRef=function(){return{current:null}},t.forwardRef=function(e){return{$$typeof:l,render:e}},t.isValidElement=P,t.lazy=function(e){return{$$typeof:u,_payload:{_status:-1,_result:e},_init:N}},t.memo=function(e,t){return{$$typeof:h,type:e,compare:void 0===t?null:t}},t.startTransition=function(e){var t=O.transition;O.transition={};try{e()}finally{O.transition=t}},t.unstable_act=function(){throw Error("act(...) is not supported in production builds of React.")},t.useCallback=function(e,t){return R.current.useCallback(e,t)},t.useContext=function(e){return R.current.useContext(e)},t.useDebugValue=function(){},t.useDeferredValue=function(e){return R.current.useDeferredValue(e)},t.useEffect=function(e,t){return R.current.useEffect(e,t)},t.useId=function(){return R.current.useId()},t.useImperativeHandle=function(e,t,n){return R.current.useImperativeHandle(e,t,n)},t.useInsertionEffect=function(e,t){return R.current.useInsertionEffect(e,t)},t.useLayoutEffect=function(e,t){return R.current.useLayoutEffect(e,t)},t.useMemo=function(e,t){return R.current.useMemo(e,t)},t.useReducer=function(e,t,n){return R.current.useReducer(e,t,n)},t.useRef=function(e){return R.current.useRef(e)},t.useState=function(e){return R.current.useState(e)},t.useSyncExternalStore=function(e,t,n){return R.current.useSyncExternalStore(e,t,n)},t.useTransition=function(){return R.current.useTransition()},t.version="18.2.0"},827378:(e,t,n)=>{e.exports=n(541535)},824246:(e,t,n)=>{e.exports=n(371426)},511151:(e,t,n)=>{n.d(t,{Zo:()=>i,ah:()=>r});var o=n(667294);const a=o.createContext({});function r(e){const t=o.useContext(a);return o.useMemo((()=>"function"==typeof e?e(t):{...t,...e}),[t,e])}const s={};function i({components:e,children:t,disableParentContext:n}){let i;return i=n?"function"==typeof e?e({}):e||s:r(e),o.createElement(a.Provider,{value:i},t)}}}]);